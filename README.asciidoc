Rigor
=====

Introduction
------------
Rigor is a framework for testing algorithms in a systematic fashion. Users can import annotated images into the database, then run an algorithm against each of them in turn, finally producing a report that can be used for evaluating the algorithm.

Images, once imported, are stored in a file tree using a unique identifier. A separate set of database tables contain the image metadata, keyed to the image files using the same identifier. Aside from image-specific attributes (size, depth, etc.), images can also have any number of tags. Tags are there to assist users in building sets of images, which can be useful for more detailed analysis of algorithms.

Each image can also have a number of annotations. Annotating an image defines the ground truth in a particular domain, such as whether the image is blurry, where text is located, or what denomination bill is shown. A single image can have annotations in different domains, and it can even have multiple annotations in the same domain (generally used when an annotation contains a boundary, and multiple regions of interest exist).

When running Rigor, by default all images and annotations in a particular domain will be run against the algorithm. This can be limited to a smaller sample using the command-line tools, or much more extensively tweaked by writing a standalone Python application which includes the Rigor libraries.

Prerequisites
-------------
- Python v2.7 or higher
- OpenCV 2.x Python bindings (for reading images)
- psycopg2 or pg8000
- PostgreSQL 9.x
- image repository, either mounted locally or accessible via HTTP(S)
- exiv2 for Python (import only)
- NumPy (to use the ObjectAreaEvaluator)
- Shapely (to use the ObjectAreaEvaluator)
- import repository mounted locally, read-write (import only)

Configuration
-------------
Copy the `rigor.ini.sample` file to `.rigor.ini` in your home directory. Commented-out values reflect the defaults; uncomment and change them to alter settings.

- The `image_repository` can either be a local path, if you have the image repository mounted locally, or it can be a base URL for fetching remote images.

You may need to set the `PYTHONPATH` to include the `python` directory in `rigor`, plus any other Python modules such as OpenCV's.

You may also need to set the `LD_LIBRARY_PATH` or `DYLD_LIBRARY_PATH` to point to any compiled algorithms that are not available systemwide.

If you are planning on importing images, you will also want to set the upload repository read-write, and set the `upload_repository` parameter to point there.

Use
---
Running
~~~~~~~
TODO: This needs to be documented better. See the `python/examples` directory for some basic demonstrations.

You can create the initial database using `tools/dbtool.py`. Run it with `-h` for help.

Importing
~~~~~~~~~
Importing images basically entails copying the image file into the repository, and updating the database with metadata, tags, and annotations. There is an import script that will do most of this automatically, when supplied with a basic metadata description file.

CAUTION: Importing images into the database should be done carefully, as it is not always easy to undo mistakes.

The `import.py` command takes a single directory, or a list of directories, and imports all of the images inside. It expects to find a `metadata.json` file inside each directory containing general metadata that applies to every file.

Here is an example file with all of the metadata fields used. Most are optional, but it is highly recommended to fill in as much information as is known, as that improves the quality of the database.

.Example `metadata.json` file
..............................................
{
  "timestamp" : "2011-02-04T21:24:56Z",    <1>
  "location" : [ -122.269241, 37.871104 ], <2>
  "tags" : [                               <3>
    "training",
    "money",
    "obscured",
    "source:berkeley_2011-02",
    "sensor:htc_nexus_one"
  ],
  "source_id" : "img_12886.jpg",           <4>
  "annotations" : [
    {
      "domain" : "money",                  <5>
      "confidence" : "2",                  <6>
      "model" : "20d",                     <7>
      "boundary" : [                       <8>
        [1, 2],
        [2, 4],
        [2, 8],
        [6, 7]
      ]
      "annotation_tags" : [
        "blindsight_created",
        "byhand",
        "multiple_words"
      ],
    }
  ]
}
..............................................

<1> The time and date (UTC) that the image was taken. The file timestamp will be used if this is not supplied here.
<2> WGS84 lon/lat Where the image was taken. Ideally, this can be extracted from EXIF data, but at the moment this isn't supported
<3> Tags are freeform. The more the merrier.
<4> Source ID is an original filename, if there is one
<5> Domain is a sort of namespace for the annotation. The algorithm to test is chosen by the domain.
<6> Confidence is the level of confidence we have in the annotation's correctness. Values should range from 1 to 5 where 1 is "unreviewed" and 5 is "publishable"
<7> The model is the actual ground truth used to compare against the returned value from an algorithm.
<8> The boundary is a list of coordinates, each defining a point in a polygonal bounding box.

A minimal metadata.json file might just have tags specified:

.Example minimal `metadata.json` file
..............................................
{
  "tags" : [
    "source:berkeley_2011-02",
    "training",
    "money",
    "obscured"
  ]
}
..............................................

It is also possible to supply a metadata file for each image. Create a file with the same name as the image, but with `.json` as the extension. For example, `img00010.jpg` would have an accompanying `img00010.json` metadata file. Anything in this file will replace anything in the directory-wide `metadata.json` file, which will replace anything automatically extracted from the image.

Once you run the `import.py` command, the images in the directory will be put into the database, and the source images will be either copied or moved to the upload tree. Periodically, those files will be moved into the official image tree, and they will then be usable. At the moment, that does mean a discrepency between the contents of the database and the filesystem, but it should be a short-lived difference. It may be fixed in the future by flagging newly-uploaded data in the database, and preventing it from being used in Rigor trials until it is marked as active.
